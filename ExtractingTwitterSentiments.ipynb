{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExtractingTwitterSentiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNXYPWF7hXF80v975Pjlroa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDave94/Stock-Prediction-DL/blob/main/ExtractingTwitterSentiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrle27PmpP3h"
      },
      "source": [
        "# Twitter Data Cleansing and Sentiment Analysis\n",
        "##### *Step 1: Cleaning Date Column. Creating Date column with YYYY-MM-DD format*\n",
        "##### *Step 2: Cleaning Tweet Content. Removing special characters, mentions, hastags, links, and other special characters from tweets*\n",
        "##### *Step 3: Sentiment Calculations. Calculating compound sentiment score for each day*\n",
        "##### *Step 4: Aggregating sentiment scores for each day (mean average) to obtain overall sentiment for each day*\n",
        "##### *Step 5: Creating final Twitter dataframe with data from all years of tweets and sentiment scores*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MMbckK0nJt6"
      },
      "source": [
        "#Installing and importing important libs\n",
        "!pip install flair\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime\n",
        "import flair\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\" , 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SVC6Qi6oI-4"
      },
      "source": [
        "#Loading raw twitter data containing Date and Tweets pertaining to Microsoft Stock\n",
        "df_2017 = pd.read_csv(\"https://raw.githubusercontent.com/DDave94/Stock-Prediction-DL/main/datasets/raw/text-query-tweets-2017.csv\")\n",
        "df_2018 = pd.read_csv(\"https://raw.githubusercontent.com/DDave94/Stock-Prediction-DL/main/datasets/raw/text-query-tweets-2018.csv\")\n",
        "df_2019 = pd.read_csv(\"https://raw.githubusercontent.com/DDave94/Stock-Prediction-DL/main/datasets/raw/text-query-tweets-2019.csv\")\n",
        "df_2020 = pd.read_csv(\"https://raw.githubusercontent.com/DDave94/Stock-Prediction-DL/main/datasets/raw/text-query-tweets-2020.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdItrWjMo600"
      },
      "source": [
        "# Step 1: Cleaning Dates\n",
        "###### *Creating Date column by removing time component, since we want to aggregrate sentiment scores on a daily basis*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpJ8-7h5ns5y"
      },
      "source": [
        "def date_generation(date):\n",
        "    # Create date object from given time format in dataframe\n",
        "    my_date = datetime.strptime(date, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
        "    return my_date.date()\n",
        "\n",
        "def date_cleanse(input_df):\n",
        "    input_df['Date'] = input_df['Datetime'].apply(lambda x: date_generation(x))\n",
        "    return input_df\n",
        "\n",
        "# Creating clean date columns\n",
        "df_2017 = date_cleanse(df_2017)\n",
        "df_2018 = date_cleanse(df_2018)\n",
        "df_2019 = date_cleanse(df_2019)\n",
        "df_2020 = date_cleanse(df_2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRW6JTK9p8KN"
      },
      "source": [
        "# Step 2: Cleaning Tweet content\n",
        "###### *Removing links, mentions, hashtags etc.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlFG1wqfucuv"
      },
      "source": [
        "def tweet_cleanse(text):\n",
        "\n",
        "    #Removing hyperlinks with text\n",
        "    text = re.sub(r'https?:\\/\\/\\S+','', text) \n",
        "\n",
        "    #Removing $ and any text appearing after\n",
        "    text = re.sub(r'\\$[A-za-z0-9]+','', text) \n",
        "\n",
        "    #Removing pattern \"Read More: and MSFT tokens\"\n",
        "    text = re.sub(r'Read more:|MSFT','', text) \n",
        "\n",
        "    #Removing @mentions\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) \n",
        "\n",
        "    #Removing = sybmol and text coming after\n",
        "    text = re.sub(r'=[\\S\\D\\s]+', '', text)\n",
        "    \n",
        "    #Removing all other special characters\n",
        "    text = re.sub('[^A-Za-z0-9?!\\']+', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def gen_tweets(input_df): \n",
        "    input_df['Tweet'] = input_df['Text'].apply(lambda x: tweet_cleanse(x))\n",
        "    return input_df\n",
        "\n",
        "#Generating clean tweets from current text\n",
        "df_2017 = gen_tweets(df_2017)\n",
        "df_2018 = gen_tweets(df_2018)\n",
        "df_2019 = gen_tweets(df_2019)\n",
        "df_2020 = gen_tweets(df_2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZyvnUwJTdNO"
      },
      "source": [
        "# Step 3: Tweet Sentiment Calculations\n",
        "###### *Generating the compound sentiment score for each tweet using distilBert sentiment classifier from Flair*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkCBm0pYUSA9",
        "outputId": "3212d1e7-f983-4fe7-8657-43ec59877e4c"
      },
      "source": [
        "#Creating sentiment model from flair\n",
        "sentiment_model = flair.models.TextClassifier.load('en-sentiment')\n",
        "\n",
        "def get_sentiment(tweet): \n",
        "    #Tokenizing the sentence\n",
        "    tweet_tokenized = flair.data.Sentence(tweet) \n",
        "    #Making prediction on tokenized sentence and extracting labels\n",
        "    sentiment_model.predict(tweet_tokenized)\n",
        "\n",
        "    #Extracting the sentiment confidence score\n",
        "    if (tweet_tokenized.labels[0].value == 'NEGATIVE'):\n",
        "        sentiment_score = -1 * (tweet_tokenized.labels[0].score)\n",
        "    else:\n",
        "        sentiment_score = tweet_tokenized.labels[0].score\n",
        "        \n",
        "    return sentiment_score\n",
        "\n",
        "#Creates a sentiment column for each tweet\n",
        "def sentiment_generation(input_df): \n",
        "    input_df['TwitterSentiment'] = input_df['Tweet'].apply(get_sentiment)\n",
        "    sentiment_df = input_df\n",
        "    return sentiment_df \n",
        "\n",
        "df_2017 = sentiment_generation(df_2017)\n",
        "df_2018 = sentiment_generation(df_2018)\n",
        "df_2019 = sentiment_generation(df_2019)\n",
        "df_2020 = sentiment_generation(df_2020)\n",
        "\n",
        "print(df_2017[['Tweet', 'TwitterSentiment']].head(10))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-20 02:53:02,664 loading file /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n",
            "                                                                                          Tweet  TwitterSentiment\n",
            "0         Lumia 550 and 650 discounted at online Microsoft Store if you can find them in stock           0.768637\n",
            "1                                                            Microsoft Dividend Stock Analysis           0.574826\n",
            "2  Tesco still has Microsoft Lumia devices in stock as well as its approved partners in the UK           0.954907\n",
            "3                                              Why is the Microsoft Store pruning Lumia stock?          -0.999738\n",
            "4                                              Why is the Microsoft Store pruning Lumia stock?          -0.999738\n",
            "5                                  3 Strengths That Make Microsoft Corporation Stock A Buy Now           0.998628\n",
            "6                                  3 Strengths That Make Microsoft Corporation Stock A Buy Now           0.998628\n",
            "7                                  3 Strengths That Make Microsoft Corporation Stock A Buy Now           0.998628\n",
            "8                         Microsoft Corporation Stock Shares Spike Down As microsoftcorporation         -0.998872\n",
            "9                         Microsoft Corporation Stock Shares Spike Down As microsoftcorporation         -0.998872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BIlsbK7qAbt"
      },
      "source": [
        "# Step 4: Sentiment Score Aggregation\n",
        "###### *Aggregating the final sentiment scores to gather scores for each day*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMsrew4CqJst"
      },
      "source": [
        "#Creates an aggregated sentiment score for each day of tweets\n",
        "def aggregated_df (input_df):\n",
        "    agg_df = input_df[['Date', 'TwitterSentiment']]\n",
        "    agg_df =  input_df.groupby([\"Date\"], as_index=False)['TwitterSentiment'].mean()\n",
        "    return agg_df\n",
        "\n",
        "final_2017 = aggregated_df(df_2017)\n",
        "final_2018 = aggregated_df(df_2018)\n",
        "final_2019 = aggregated_df(df_2019)\n",
        "final_2020 = aggregated_df(df_2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKzZLKb23bot"
      },
      "source": [
        "# Step 5: Creating full input dataframe for further analysis and stock price predictions\n",
        "###### *Combining twitter data from 2017,2018,2019,2020*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAONYIidb4w2",
        "outputId": "2940a5a6-4313-491b-b10f-8177a907205c"
      },
      "source": [
        "#Creating full twitter data\n",
        "twitter_data = final_2017.append([final_2018, final_2019, final_2020])\n",
        "print(twitter_data.shape)\n",
        "print(twitter_data.head())\n",
        "print(twitter_data.tail())\n",
        "\n",
        "twitter_data.to_csv('/content/twitter_sentiment_data.csv', index=False, encoding= 'utf-8-sig') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1340, 2)\n",
            "         Date  TwitterSentiment\n",
            "0  2017-01-01          0.768637\n",
            "1  2017-01-02         -0.117436\n",
            "2  2017-01-03          0.499253\n",
            "3  2017-01-04         -0.995186\n",
            "4  2017-01-05          0.318698\n",
            "           Date  TwitterSentiment\n",
            "359  2020-12-25          0.016382\n",
            "360  2020-12-26          0.979240\n",
            "361  2020-12-27          0.408995\n",
            "362  2020-12-28          0.544929\n",
            "363  2020-12-29         -0.373856\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}